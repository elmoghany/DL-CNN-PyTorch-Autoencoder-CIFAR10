{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elmog\\AppData\\Local\\Temp\\ipykernel_27816\\3517338504.py:20: DeprecationWarning: `set_matplotlib_formats` is deprecated since IPython 7.23, directly use `matplotlib_inline.backend_inline.set_matplotlib_formats()`\n",
      "  set_matplotlib_formats('svg')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import scipy.stats as stats\n",
    "import copy\n",
    "import keras\n",
    "\n",
    "#for importing data\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset, Subset\n",
    "import pandas as pd\n",
    "\n",
    "#for data visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "#GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformations\n",
    "# Step 0 : normalize\n",
    "# Step 1 : convert to tensor\n",
    "transform = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(\n",
    "        mean=[0.5,0.5,0.5],\n",
    "        std =[0.5,0.5,0.5]\n",
    "        ),\n",
    "    #T.Resize()\n",
    "    #T.RandomHorizontalFlip(p=0.5)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Step 2: convert into pytorch dataset \n",
    "train_data = torchvision.datasets.CIFAR10(\n",
    "                                root='./data', \n",
    "                                download=True, \n",
    "                                train=True, \n",
    "                                transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsize = 32\n",
    "train_loader = DataLoader(train_data, batch_size=batchsize, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_dataT = torch.tensor(reshaped_data).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "#inChans  = 3 # RGB\n",
    "#outChans = 15\n",
    "#krnSize  = 5 # should be an odd number\n",
    "#stride   = 1\n",
    "#padding  = 0\n",
    "\n",
    "#imsize   = [256,256]\n",
    "\n",
    "## create the instance\n",
    "#c = nn.Conv2d         (inChans,outChans,krnSize,stride,padding)\n",
    "#c = nn.ConvTranspose2d(inChans,outChans,krnSize,stride,padding)\n",
    "\n",
    "# create an image\n",
    "#img = torch.rand(1,inChans,imsize[0],imsize[1])\n",
    "\n",
    "# run convolution and compute its shape\n",
    "#resimg = c(img)\n",
    "#empSize = torch.squeeze(resimg).shape\n",
    "\n",
    "# compute the size of the result according to the formula\n",
    "#expectSize = np.array([outChans,0,0],dtype=int)\n",
    "#expectSize[1] = np.floor( (imsize[0]+2*padding-krnSize)/stride[0] ) + 1\n",
    "#expectSize[2] = np.floor( (imsize[1]+2*padding-krnSize)/stride[1] ) + 1\n",
    "\n",
    "# check the size of the output\n",
    "#print(f'Expected size: {expectSize}')\n",
    "#print(f'Empirical size: {list(empSize)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **) size of transpose convolution formula \"to calculate the image size of the transpose convolution\"\n",
    "# **) # of pixels in output image = Stride  * (# of pixels in input image - 1) + # of pixels in kernel height    - 2 * Padding\n",
    "# **)                       Nh    = Sh      * (Mh                         - 1) + K                               - 2*P\n",
    "# #\n",
    "# *) size of convolution formula \"to calculate the image size of convolution\"\n",
    "# *) # of pixels in current layer = Floor ( (# of pixels in previous layer  + 2*Padding - # of pixels in kernel height) / Stride ) + 1\n",
    "# *)                        Nh    = Floor ( ( Mh                            + 2*P       - K                           ) / Sh     ) + 1\n",
    "# *) expectSize = np.array([outChans, 0, 0], dtype=int)\n",
    "# *) expectsize[1] = np.floor( (imsize[0] + 2*padding - krnSize) / stride[0] ) + 1\n",
    "# *) expectsize[2] = np.floor( (imsize[1] + 2*padding - krnSize) / s/tride[1] ) + 1\n",
    "# #\n",
    "# 1) Image (channels   X Width  X Height)\n",
    "# 1) Image (1          X i/p 28 X i/p 28)\n",
    "# #\n",
    "# 2) Conv1 (# of feature maps kernels   X o/p Width X o/p Height)\n",
    "# 2) Conv1 ( 10                         X 26        X 26        ) #lost 1 pixel left & 1 pixel right (1 pixel top & 1 pixel bottom) \n",
    "# #\n",
    "# 3) maxpool1 (# of feature maps kernels X o/p width X o/p Height)\n",
    "# 3) maxpool1 (10                        X 13        X 13        ) #2x2 maxpool * 26x26 = 13 x 13\n",
    "# #\n",
    "# 4) Conv2 (# of feature maps kernels   X o/p Width X o/p Height)\n",
    "# 4) Conv2 (20                          X 11        X 11        )\n",
    "# #\n",
    "# 5) maxpool2 (# of feature maps kernels X o/p width X o/p Height)\n",
    "# 5) maxpool2 (20                        X 5        X 5        ) #2x2 maxpool * 26x26 = 13 x 13\n",
    "# #\n",
    "# 6) ANN layer (1X50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Deep Learning Model\n",
    "def createTheNet(printtoggle=False):\n",
    "    class cnnClassNet(nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            \n",
    "            self.print = printtoggle\n",
    "            \n",
    "            ### --- Encoding Layer --- ###\n",
    "            \n",
    "            inChans  = 3 # RGB\n",
    "            outChans = 16 # feature maps # of kernels\n",
    "            krnSize  = 4 # odd number\n",
    "            padding  = 1 # square if single input\n",
    "            stride   = 2 # use maxpool instead of stride ... so stride = 1\n",
    "            \n",
    "            # First Convolution Layer\n",
    "            self.enc_conv1  = nn.Conv2d(inChans,    outChans,    krnSize, padding, stride)\n",
    "            # output size = np.floor( (imsize[0]+2*padding-krnSize)/stride[0] ) + 1\n",
    "            # output size = floor( (32 + 2*1 - 3) / 1 ) + 1 = 32\n",
    "            # output size = 32/2 = 16 b/c of avgpool\n",
    "            \n",
    "            # Second Convolution Layer\n",
    "            self.enc_conv2  = nn.Conv2d(outChans,   outChans*2,  krnSize, padding, stride)\n",
    "            # output size = floor( (16 + 2*0 - 3) / 1 ) + 1 = 14\n",
    "            # output size = 14/2 = 7 b/c of avgpool\n",
    "\n",
    "            # Latent Layer\n",
    "            self.enc_latent  = nn.Conv2d(outChans*2,outChans*2*2,krnSize, padding, stride)\n",
    "            # output size = floor( (7 + 2*0 - 3) / 1 ) + 1 = 5\n",
    "            # output size = 5/2 = 2 b/c of avgpool\n",
    "\n",
    "            ### --- Decoding Layer --- ###\n",
    "            \n",
    "            # Latent Layer\n",
    "            self.dec_latent  = nn.ConvTranspose2d(outChans*2*2,outChans*2,krnSize, padding, stride)\n",
    "            \n",
    "            # First Convolution Transpose Layer\n",
    "            self.dec_conv1   = nn.ConvTranspose2d(outChans*2  ,outChans  ,krnSize, padding, stride)\n",
    "\n",
    "            # Second Convolution Transpose Layer\n",
    "            self.dec_conv2   = nn.ConvTranspose2d(outChans    ,inChans   ,krnSize, padding, stride)\n",
    "            \n",
    "            \n",
    "        def forward(self, x):\n",
    "            \n",
    "            if self.print: print(f'Input: {list(x.shape)}')\n",
    "            \n",
    "            # Encoding Layer\n",
    "            #CPBR block\n",
    "            x = F.leaky_relu( self.enc_conv1(x))\n",
    "            if self.print: print(f'First Enc Conv: {list(x.shape)}')\n",
    "            \n",
    "            x = F.leaky_relu( self.enc_conv2(x))\n",
    "            if self.print: print(f'Second Enc Conv: {list(x.shape)}')\n",
    "\n",
    "            x = F.leaky_relu( self.enc_latent(x))\n",
    "            if self.print: print(f'Latent Enc: {list(x.shape)}')\n",
    "            \n",
    "            x = F.leaky_relu( self.dec_latent(x))\n",
    "            if self.print: print(f'Latent Dec: {list(x.shape)}')\n",
    "            \n",
    "            x = F.leaky_relu( self.dec_conv1(x))\n",
    "            if self.print: print(f'First Dec Conv: {list(x.shape)}')\n",
    "\n",
    "            x = ( self.dec_conv2(x))\n",
    "            if self.print: print(f'Second Dec Conv: {list(x.shape)}')\n",
    "                        \n",
    "            return x\n",
    "        \n",
    "    modelInstance = cnnClassNet().to(device)\n",
    "    \n",
    "    lossfun = nn.MSELoss()\n",
    "    \n",
    "    optimizer = torch.optim.Adam(modelInstance.parameters(), lr=0.001, weight_decay=1e-5)#, betas=(0.9, 0.999), eps=1e-8)\n",
    "    \n",
    "    return modelInstance, lossfun, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Model\n",
    "\n",
    "def trainTheModel(trainedModel, lossfun, optimizer, epochs=20):\n",
    "    \n",
    "    #number of epochs to train\n",
    "    numepochs = epochs\n",
    "    trainedModel.train()\n",
    "    trainLoss   = []\n",
    "    \n",
    "    for epochi in range(numepochs):\n",
    "        \n",
    "        batchLoss = []\n",
    "        #get a permuted index vector\n",
    "                \n",
    "        for X, y in train_loader:\n",
    "            \n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            \n",
    "            #forward pass & loss\n",
    "            yHat = trainedModel(X)\n",
    "            loss = lossfun(yHat, X)\n",
    "            \n",
    "            #backprop\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            #losses in this batch\n",
    "            batchLoss.append(loss.item())\n",
    "            \n",
    "        trainLoss.append(np.mean(batchLoss))\n",
    "    \n",
    "    return trainLoss, trainedModel            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch.nn' has no attribute 'nn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[148], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Train the Model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m myModelInstance, lossfun, optimizer \u001b[38;5;241m=\u001b[39m \u001b[43mcreateTheNet\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m trainLoss, trainedModel \u001b[38;5;241m=\u001b[39m trainTheModel(myModelInstance, lossfun, optimizer)\n",
      "Cell \u001b[1;32mIn[146], line 73\u001b[0m, in \u001b[0;36mcreateTheNet\u001b[1;34m(printtoggle)\u001b[0m\n\u001b[0;32m     69\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[0;32m     71\u001b[0m modelInstance \u001b[38;5;241m=\u001b[39m cnnClassNet()\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 73\u001b[0m lossfun \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241m.\u001b[39mMSELoss()\n\u001b[0;32m     75\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(modelInstance\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m, weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-5\u001b[39m)\u001b[38;5;66;03m#, betas=(0.9, 0.999), eps=1e-8)\u001b[39;00m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m modelInstance, lossfun, optimizer\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'torch.nn' has no attribute 'nn'"
     ]
    }
   ],
   "source": [
    "# Train the Model\n",
    "myModelInstance, lossfun, optimizer = createTheNet(True)\n",
    "trainLoss, trainedModel = trainTheModel(myModelInstance, lossfun, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
