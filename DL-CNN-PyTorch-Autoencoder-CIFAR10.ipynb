{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elmog\\AppData\\Local\\Temp\\ipykernel_27816\\3517338504.py:20: DeprecationWarning: `set_matplotlib_formats` is deprecated since IPython 7.23, directly use `matplotlib_inline.backend_inline.set_matplotlib_formats()`\n",
      "  set_matplotlib_formats('svg')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import scipy.stats as stats\n",
    "import copy\n",
    "import keras\n",
    "\n",
    "#for importing data\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset, Subset\n",
    "import pandas as pd\n",
    "\n",
    "#for data visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "#GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformations\n",
    "# Step 0 : normalize\n",
    "# Step 1 : convert to tensor\n",
    "transform = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(\n",
    "        mean=[0.5,0.5,0.5],\n",
    "        std =[0.5,0.5,0.5]\n",
    "        ),\n",
    "    #T.Resize()\n",
    "    #T.RandomHorizontalFlip(p=0.5)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Step 2: convert into pytorch dataset \n",
    "train_data = torchvision.datasets.CIFAR10(\n",
    "                                root='./data', \n",
    "                                download=True, \n",
    "                                train=True, \n",
    "                                transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsize = 32\n",
    "train_loader = DataLoader(train_data, batch_size=batchsize, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_dataT = torch.tensor(reshaped_data).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "#inChans  = 3 # RGB\n",
    "#outChans = 15\n",
    "#krnSize  = 5 # should be an odd number\n",
    "#stride   = 1\n",
    "#padding  = 0\n",
    "\n",
    "#imsize   = [256,256]\n",
    "\n",
    "## create the instance\n",
    "#c = nn.Conv2d         (inChans,outChans,krnSize,stride,padding)\n",
    "#c = nn.ConvTranspose2d(inChans,outChans,krnSize,stride,padding)\n",
    "\n",
    "# create an image\n",
    "#img = torch.rand(1,inChans,imsize[0],imsize[1])\n",
    "\n",
    "# run convolution and compute its shape\n",
    "#resimg = c(img)\n",
    "#empSize = torch.squeeze(resimg).shape\n",
    "\n",
    "# compute the size of the result according to the formula\n",
    "#expectSize = np.array([outChans,0,0],dtype=int)\n",
    "#expectSize[1] = np.floor( (imsize[0]+2*padding-krnSize)/stride[0] ) + 1\n",
    "#expectSize[2] = np.floor( (imsize[1]+2*padding-krnSize)/stride[1] ) + 1\n",
    "\n",
    "# check the size of the output\n",
    "#print(f'Expected size: {expectSize}')\n",
    "#print(f'Empirical size: {list(empSize)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **) size of transpose convolution formula \"to calculate the image size of the transpose convolution\"\n",
    "# **) # of pixels in output image = Stride  * (# of pixels in input image - 1) + # of pixels in kernel height    - 2 * Padding\n",
    "# **)                       Nh    = Sh      * (Mh                         - 1) + K                               - 2*P\n",
    "# #\n",
    "# *) size of convolution formula \"to calculate the image size of convolution\"\n",
    "# *) # of pixels in current layer = Floor ( (# of pixels in previous layer  + 2*Padding - # of pixels in kernel height) / Stride ) + 1\n",
    "# *)                        Nh    = Floor ( ( Mh                            + 2*P       - K                           ) / Sh     ) + 1\n",
    "# *) expectSize = np.array([outChans, 0, 0], dtype=int)\n",
    "# *) expectsize[1] = np.floor( (imsize[0] + 2*padding - krnSize) / stride[0] ) + 1\n",
    "# *) expectsize[2] = np.floor( (imsize[1] + 2*padding - krnSize) / s/tride[1] ) + 1\n",
    "# #\n",
    "# 1) Image (channels   X Width  X Height)\n",
    "# 1) Image (1          X i/p 28 X i/p 28)\n",
    "# #\n",
    "# 2) Conv1 (# of feature maps kernels   X o/p Width X o/p Height)\n",
    "# 2) Conv1 ( 10                         X 26        X 26        ) #lost 1 pixel left & 1 pixel right (1 pixel top & 1 pixel bottom) \n",
    "# #\n",
    "# 3) maxpool1 (# of feature maps kernels X o/p width X o/p Height)\n",
    "# 3) maxpool1 (10                        X 13        X 13        ) #2x2 maxpool * 26x26 = 13 x 13\n",
    "# #\n",
    "# 4) Conv2 (# of feature maps kernels   X o/p Width X o/p Height)\n",
    "# 4) Conv2 (20                          X 11        X 11        )\n",
    "# #\n",
    "# 5) maxpool2 (# of feature maps kernels X o/p width X o/p Height)\n",
    "# 5) maxpool2 (20                        X 5        X 5        ) #2x2 maxpool * 26x26 = 13 x 13\n",
    "# #\n",
    "# 6) ANN layer (1X50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Deep Learning Model\n",
    "def createTheNet(printtoggle=False):\n",
    "    class cnnClassNet(nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            \n",
    "            self.print = printtoggle\n",
    "            \n",
    "            ### --- Encoding Layer --- ###\n",
    "            \n",
    "            inChans  = 3 # RGB\n",
    "            outChans = 16 # feature maps # of kernels\n",
    "            krnSize  = 4 # odd number\n",
    "            padding  = 1 # square if single input\n",
    "            stride   = 2 # use maxpool instead of stride ... so stride = 1\n",
    "            \n",
    "            # First Convolution Layer\n",
    "            self.enc_conv1  = nn.Conv2d(inChans,    outChans,    krnSize, padding, stride)\n",
    "            # output size = np.floor( (imsize[0]+2*padding-krnSize)/stride[0] ) + 1\n",
    "            # output size = floor( (32 + 2*1 - 3) / 1 ) + 1 = 32\n",
    "            # output size = 32/2 = 16 b/c of avgpool\n",
    "            \n",
    "            # Second Convolution Layer\n",
    "            self.enc_conv2  = nn.Conv2d(outChans,   outChans*2,  krnSize, padding, stride)\n",
    "            # output size = floor( (16 + 2*0 - 3) / 1 ) + 1 = 14\n",
    "            # output size = 14/2 = 7 b/c of avgpool\n",
    "\n",
    "            # Latent Layer\n",
    "            self.enc_latent  = nn.Conv2d(outChans*2,outChans*2*2,krnSize, padding, stride)\n",
    "            # output size = floor( (7 + 2*0 - 3) / 1 ) + 1 = 5\n",
    "            # output size = 5/2 = 2 b/c of avgpool\n",
    "\n",
    "            ### --- Decoding Layer --- ###\n",
    "            \n",
    "            # Latent Layer\n",
    "            self.dec_latent  = nn.ConvTranspose2d(outChans*2*2,outChans*2,krnSize, padding, stride)\n",
    "            \n",
    "            # First Convolution Transpose Layer\n",
    "            self.dec_conv1   = nn.ConvTranspose2d(outChans*2  ,outChans  ,krnSize, padding, stride)\n",
    "\n",
    "            # Second Convolution Transpose Layer\n",
    "            self.dec_conv2   = nn.ConvTranspose2d(outChans    ,inChans   ,krnSize, padding, stride)\n",
    "            \n",
    "            \n",
    "        def forward(self, x):\n",
    "            \n",
    "            if self.print: print(f'Input: {list(x.shape)}')\n",
    "            \n",
    "            # Encoding Layer\n",
    "            #CPBR block\n",
    "            x = F.leaky_relu( self.enc_conv1(x))\n",
    "            if self.print: print(f'First Enc Conv: {list(x.shape)}')\n",
    "            \n",
    "            x = F.leaky_relu( self.enc_conv2(x))\n",
    "            if self.print: print(f'Second Enc Conv: {list(x.shape)}')\n",
    "\n",
    "            x = F.leaky_relu( self.enc_latent(x))\n",
    "            if self.print: print(f'Latent Enc: {list(x.shape)}')\n",
    "            \n",
    "            x = F.leaky_relu( self.dec_latent(x))\n",
    "            if self.print: print(f'Latent Dec: {list(x.shape)}')\n",
    "            \n",
    "            x = F.leaky_relu( self.dec_conv1(x))\n",
    "            if self.print: print(f'First Dec Conv: {list(x.shape)}')\n",
    "\n",
    "            x = ( self.dec_conv2(x))\n",
    "            if self.print: print(f'Second Dec Conv: {list(x.shape)}')\n",
    "                        \n",
    "            return x\n",
    "        \n",
    "    modelInstance = cnnClassNet().to(device)\n",
    "    \n",
    "    lossfun = nn.MSELoss()\n",
    "    \n",
    "    optimizer = torch.optim.Adam(modelInstance.parameters(), lr=0.001, weight_decay=1e-5)#, betas=(0.9, 0.999), eps=1e-8)\n",
    "    \n",
    "    return modelInstance, lossfun, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Model\n",
    "\n",
    "def trainTheModel(trainedModel, lossfun, optimizer, epochs=20):\n",
    "    \n",
    "    #number of epochs to train\n",
    "    numepochs = epochs\n",
    "    trainedModel.train()\n",
    "    trainLoss   = []\n",
    "    \n",
    "    for epochi in range(numepochs):\n",
    "        \n",
    "        batchLoss = []\n",
    "        #get a permuted index vector\n",
    "                \n",
    "        for X, y in train_loader:\n",
    "            \n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            \n",
    "            #forward pass & loss\n",
    "            yHat = trainedModel(X)\n",
    "            loss = lossfun(yHat, X)\n",
    "            \n",
    "            #backprop\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            #losses in this batch\n",
    "            batchLoss.append(loss.item())\n",
    "            \n",
    "        trainLoss.append(np.mean(batchLoss))\n",
    "    \n",
    "    return trainLoss, trainedModel            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the Model & train\n",
    "myModelInstance2, lossfun2, optimizer2 = createTheNet(True)\n",
    "trainLoss2, trainedModel2 = trainTheModel(myModelInstance2, lossfun2, optimizer2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: [32, 3, 32, 32]\n",
      "First Enc Conv: [32, 16, 33, 33]\n",
      "Second Enc Conv: [32, 32, 34, 34]\n",
      "Latent Enc: [32, 64, 35, 35]\n",
      "Latent Dec: [32, 32, 34, 34]\n",
      "First Dec Conv: [32, 16, 33, 33]\n",
      "Second Dec Conv: [32, 3, 32, 32]\n",
      "Input: [32, 3, 32, 32]\n",
      "First Enc Conv: [32, 16, 33, 33]\n",
      "Second Enc Conv: [32, 32, 34, 34]\n",
      "Latent Enc: [32, 64, 35, 35]\n",
      "Latent Dec: [32, 32, 34, 34]\n",
      "First Dec Conv: [32, 16, 33, 33]\n",
      "Second Dec Conv: [32, 3, 32, 32]\n",
      "Input: [32, 3, 32, 32]\n",
      "First Enc Conv: [32, 16, 33, 33]\n",
      "Second Enc Conv: [32, 32, 34, 34]\n",
      "Latent Enc: [32, 64, 35, 35]\n",
      "Latent Dec: [32, 32, 34, 34]\n",
      "First Dec Conv: [32, 16, 33, 33]\n",
      "Second Dec Conv: [32, 3, 32, 32]\n",
      "Input: [32, 3, 32, 32]\n",
      "First Enc Conv: [32, 16, 33, 33]\n",
      "Second Enc Conv: [32, 32, 34, 34]\n",
      "Latent Enc: [32, 64, 35, 35]\n",
      "Latent Dec: [32, 32, 34, 34]\n",
      "First Dec Conv: [32, 16, 33, 33]\n",
      "Second Dec Conv: [32, 3, 32, 32]\n",
      "Input: [32, 3, 32, 32]\n",
      "First Enc Conv: [32, 16, 33, 33]\n",
      "Second Enc Conv: [32, 32, 34, 34]\n",
      "Latent Enc: [32, 64, 35, 35]\n",
      "Latent Dec: [32, 32, 34, 34]\n",
      "First Dec Conv: [32, 16, 33, 33]\n",
      "Second Dec Conv: [32, 3, 32, 32]\n",
      "Input: [32, 3, 32, 32]\n",
      "First Enc Conv: [32, 16, 33, 33]\n",
      "Second Enc Conv: [32, 32, 34, 34]\n",
      "Latent Enc: [32, 64, 35, 35]\n",
      "Latent Dec: [32, 32, 34, 34]\n",
      "First Dec Conv: [32, 16, 33, 33]\n",
      "Second Dec Conv: [32, 3, 32, 32]\n",
      "Input: [32, 3, 32, 32]\n",
      "First Enc Conv: [32, 16, 33, 33]\n",
      "Second Enc Conv: [32, 32, 34, 34]\n",
      "Latent Enc: [32, 64, 35, 35]\n",
      "Latent Dec: [32, 32, 34, 34]\n",
      "First Dec Conv: [32, 16, 33, 33]\n",
      "Second Dec Conv: [32, 3, 32, 32]\n",
      "Input: [32, 3, 32, 32]\n",
      "First Enc Conv: [32, 16, 33, 33]\n",
      "Second Enc Conv: [32, 32, 34, 34]\n",
      "Latent Enc: [32, 64, 35, 35]\n",
      "Latent Dec: [32, 32, 34, 34]\n",
      "First Dec Conv: [32, 16, 33, 33]\n",
      "Second Dec Conv: [32, 3, 32, 32]\n",
      "Input: [32, 3, 32, 32]\n",
      "First Enc Conv: [32, 16, 33, 33]\n",
      "Second Enc Conv: [32, 32, 34, 34]\n",
      "Latent Enc: [32, 64, 35, 35]\n",
      "Latent Dec: [32, 32, 34, 34]\n",
      "First Dec Conv: [32, 16, 33, 33]\n",
      "Second Dec Conv: [32, 3, 32, 32]\n",
      "Input: [32, 3, 32, 32]\n",
      "First Enc Conv: [32, 16, 33, 33]\n",
      "Second Enc Conv: [32, 32, 34, 34]\n",
      "Latent Enc: [32, 64, 35, 35]\n",
      "Latent Dec: [32, 32, 34, 34]\n",
      "First Dec Conv: [32, 16, 33, 33]\n",
      "Second Dec Conv: [32, 3, 32, 32]\n",
      "Input: [32, 3, 32, 32]\n",
      "First Enc Conv: [32, 16, 33, 33]\n",
      "Second Enc Conv: [32, 32, 34, 34]\n",
      "Latent Enc: [32, 64, 35, 35]\n",
      "Latent Dec: [32, 32, 34, 34]\n",
      "First Dec Conv: [32, 16, 33, 33]\n",
      "Second Dec Conv: [32, 3, 32, 32]\n",
      "Input: [32, 3, 32, 32]\n",
      "First Enc Conv: [32, 16, 33, 33]\n",
      "Second Enc Conv: [32, 32, 34, 34]\n",
      "Latent Enc: [32, 64, 35, 35]\n",
      "Latent Dec: [32, 32, 34, 34]\n",
      "First Dec Conv: [32, 16, 33, 33]\n",
      "Second Dec Conv: [32, 3, 32, 32]\n",
      "Input: [32, 3, 32, 32]\n",
      "First Enc Conv: [32, 16, 33, 33]\n",
      "Second Enc Conv: [32, 32, 34, 34]\n",
      "Latent Enc: [32, 64, 35, 35]\n",
      "Latent Dec: [32, 32, 34, 34]\n",
      "First Dec Conv: [32, 16, 33, 33]\n",
      "Second Dec Conv: [32, 3, 32, 32]\n",
      "Input: [32, 3, 32, 32]\n",
      "First Enc Conv: [32, 16, 33, 33]\n",
      "Second Enc Conv: [32, 32, 34, 34]\n",
      "Latent Enc: [32, 64, 35, 35]\n",
      "Latent Dec: [32, 32, 34, 34]\n",
      "First Dec Conv: [32, 16, 33, 33]\n",
      "Second Dec Conv: [32, 3, 32, 32]\n",
      "Input: [32, 3, 32, 32]\n",
      "First Enc Conv: [32, 16, 33, 33]\n",
      "Second Enc Conv: [32, 32, 34, 34]\n",
      "Latent Enc: [32, 64, 35, 35]\n",
      "Latent Dec: [32, 32, 34, 34]\n",
      "First Dec Conv: [32, 16, 33, 33]\n",
      "Second Dec Conv: [32, 3, 32, 32]\n",
      "Input: [32, 3, 32, 32]\n",
      "First Enc Conv: [32, 16, 33, 33]\n",
      "Second Enc Conv: [32, 32, 34, 34]\n",
      "Latent Enc: [32, 64, 35, 35]\n",
      "Latent Dec: [32, 32, 34, 34]\n",
      "First Dec Conv: [32, 16, 33, 33]\n",
      "Second Dec Conv: [32, 3, 32, 32]\n",
      "Input: [32, 3, 32, 32]\n",
      "First Enc Conv: [32, 16, 33, 33]\n",
      "Second Enc Conv: [32, 32, 34, 34]\n",
      "Latent Enc: [32, 64, 35, 35]\n",
      "Latent Dec: [32, 32, 34, 34]\n",
      "First Dec Conv: [32, 16, 33, 33]\n",
      "Second Dec Conv: [32, 3, 32, 32]\n",
      "Input: [32, 3, 32, 32]\n",
      "First Enc Conv: [32, 16, 33, 33]\n",
      "Second Enc Conv: [32, 32, 34, 34]\n",
      "Latent Enc: [32, 64, 35, 35]\n",
      "Latent Dec: [32, 32, 34, 34]\n",
      "First Dec Conv: [32, 16, 33, 33]\n",
      "Second Dec Conv: [32, 3, 32, 32]\n",
      "Input: [32, 3, 32, 32]\n",
      "First Enc Conv: [32, 16, 33, 33]\n",
      "Second Enc Conv: [32, 32, 34, 34]\n",
      "Latent Enc: [32, 64, 35, 35]\n",
      "Latent Dec: [32, 32, 34, 34]\n",
      "First Dec Conv: [32, 16, 33, 33]\n",
      "Second Dec Conv: [32, 3, 32, 32]\n",
      "Input: [32, 3, 32, 32]\n",
      "First Enc Conv: [32, 16, 33, 33]\n",
      "Second Enc Conv: [32, 32, 34, 34]\n",
      "Latent Enc: [32, 64, 35, 35]\n",
      "Latent Dec: [32, 32, 34, 34]\n",
      "First Dec Conv: [32, 16, 33, 33]\n",
      "Second Dec Conv: [32, 3, 32, 32]\n",
      "Input: [32, 3, 32, 32]\n",
      "First Enc Conv: [32, 16, 33, 33]\n",
      "Second Enc Conv: [32, 32, 34, 34]\n",
      "Latent Enc: [32, 64, 35, 35]\n",
      "Latent Dec: [32, 32, 34, 34]\n",
      "First Dec Conv: [32, 16, 33, 33]\n",
      "Second Dec Conv: [32, 3, 32, 32]\n",
      "Input: [32, 3, 32, 32]\n",
      "First Enc Conv: [32, 16, 33, 33]\n",
      "Second Enc Conv: [32, 32, 34, 34]\n",
      "Latent Enc: [32, 64, 35, 35]\n",
      "Latent Dec: [32, 32, 34, 34]\n",
      "First Dec Conv: [32, 16, 33, 33]\n",
      "Second Dec Conv: [32, 3, 32, 32]\n",
      "Input: [32, 3, 32, 32]\n",
      "First Enc Conv: [32, 16, 33, 33]\n",
      "Second Enc Conv: [32, 32, 34, 34]\n",
      "Latent Enc: [32, 64, 35, 35]\n",
      "Latent Dec: [32, 32, 34, 34]\n",
      "First Dec Conv: [32, 16, 33, 33]\n",
      "Second Dec Conv: [32, 3, 32, 32]\n",
      "Input: [32, 3, 32, 32]\n",
      "First Enc Conv: [32, 16, 33, 33]\n",
      "Second Enc Conv: [32, 32, 34, 34]\n",
      "Latent Enc: [32, 64, 35, 35]\n",
      "Latent Dec: [32, 32, 34, 34]\n",
      "First Dec Conv: [32, 16, 33, 33]\n",
      "Second Dec Conv: [32, 3, 32, 32]\n",
      "Input: [32, 3, 32, 32]\n",
      "First Enc Conv: [32, 16, 33, 33]\n",
      "Second Enc Conv: [32, 32, 34, 34]\n",
      "Latent Enc: [32, 64, 35, 35]\n",
      "Latent Dec: [32, 32, 34, 34]\n",
      "First Dec Conv: [32, 16, 33, 33]\n",
      "Second Dec Conv: [32, 3, 32, 32]\n",
      "Input: [32, 3, 32, 32]\n",
      "First Enc Conv: [32, 16, 33, 33]\n",
      "Second Enc Conv: [32, 32, 34, 34]\n",
      "Latent Enc: [32, 64, 35, 35]\n",
      "Latent Dec: [32, 32, 34, 34]\n",
      "First Dec Conv: [32, 16, 33, 33]\n",
      "Second Dec Conv: [32, 3, 32, 32]\n",
      "Input: [32, 3, 32, 32]\n",
      "First Enc Conv: [32, 16, 33, 33]\n",
      "Second Enc Conv: [32, 32, 34, 34]\n",
      "Latent Enc: [32, 64, 35, 35]\n",
      "Latent Dec: [32, 32, 34, 34]\n",
      "First Dec Conv: [32, 16, 33, 33]\n",
      "Second Dec Conv: [32, 3, 32, 32]\n",
      "Input: [32, 3, 32, 32]\n",
      "First Enc Conv: [32, 16, 33, 33]\n",
      "Second Enc Conv: [32, 32, 34, 34]\n",
      "Latent Enc: [32, 64, 35, 35]\n",
      "Latent Dec: [32, 32, 34, 34]\n",
      "First Dec Conv: [32, 16, 33, 33]\n",
      "Second Dec Conv: [32, 3, 32, 32]\n",
      "Input: [32, 3, 32, 32]\n",
      "First Enc Conv: [32, 16, 33, 33]\n",
      "Second Enc Conv: [32, 32, 34, 34]\n",
      "Latent Enc: [32, 64, 35, 35]\n",
      "Latent Dec: [32, 32, 34, 34]\n",
      "First Dec Conv: [32, 16, 33, 33]\n",
      "Second Dec Conv: [32, 3, 32, 32]\n",
      "Input: [32, 3, 32, 32]\n",
      "First Enc Conv: [32, 16, 33, 33]\n",
      "Second Enc Conv: [32, 32, 34, 34]\n",
      "Latent Enc: [32, 64, 35, 35]\n",
      "Latent Dec: [32, 32, 34, 34]\n",
      "First Dec Conv: [32, 16, 33, 33]\n",
      "Second Dec Conv: [32, 3, 32, 32]\n",
      "Input: [32, 3, 32, 32]\n",
      "First Enc Conv: [32, 16, 33, 33]\n",
      "Second Enc Conv: [32, 32, 34, 34]\n",
      "Latent Enc: [32, 64, 35, 35]\n",
      "Latent Dec: [32, 32, 34, 34]\n",
      "First Dec Conv: [32, 16, 33, 33]\n",
      "Second Dec Conv: [32, 3, 32, 32]\n",
      "Input: [32, 3, 32, 32]\n",
      "First Enc Conv: [32, 16, 33, 33]\n",
      "Second Enc Conv: [32, 32, 34, 34]\n",
      "Latent Enc: [32, 64, 35, 35]\n",
      "Latent Dec: [32, 32, 34, 34]\n",
      "First Dec Conv: [32, 16, 33, 33]\n",
      "Second Dec Conv: [32, 3, 32, 32]\n",
      "Input: [32, 3, 32, 32]\n",
      "First Enc Conv: [32, 16, 33, 33]\n",
      "Second Enc Conv: [32, 32, 34, 34]\n",
      "Latent Enc: [32, 64, 35, 35]\n",
      "Latent Dec: [32, 32, 34, 34]\n",
      "First Dec Conv: [32, 16, 33, 33]\n",
      "Second Dec Conv: [32, 3, 32, 32]\n",
      "Input: [32, 3, 32, 32]\n",
      "First Enc Conv: [32, 16, 33, 33]\n",
      "Second Enc Conv: [32, 32, 34, 34]\n",
      "Latent Enc: [32, 64, 35, 35]\n",
      "Latent Dec: [32, 32, 34, 34]\n",
      "First Dec Conv: [32, 16, 33, 33]\n",
      "Second Dec Conv: [32, 3, 32, 32]\n",
      "Input: [32, 3, 32, 32]\n",
      "First Enc Conv: [32, 16, 33, 33]\n",
      "Second Enc Conv: [32, 32, 34, 34]\n",
      "Latent Enc: [32, 64, 35, 35]\n",
      "Latent Dec: [32, 32, 34, 34]\n",
      "First Dec Conv: [32, 16, 33, 33]\n",
      "Second Dec Conv: [32, 3, 32, 32]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[165], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Train the Model\u001b[39;00m\n\u001b[0;32m      2\u001b[0m myModelInstance, lossfun, optimizer \u001b[38;5;241m=\u001b[39m createTheNet(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m----> 3\u001b[0m trainLoss, trainedModel \u001b[38;5;241m=\u001b[39m \u001b[43mtrainTheModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmyModelInstance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlossfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[163], line 15\u001b[0m, in \u001b[0;36mtrainTheModel\u001b[1;34m(trainedModel, lossfun, optimizer, epochs)\u001b[0m\n\u001b[0;32m     12\u001b[0m batchLoss \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m#get a permuted index vector\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m X, y \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[0;32m     17\u001b[0m     X \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     18\u001b[0m     y \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[1;32mc:\\Users\\elmog\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\elmog\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\elmog\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\elmog\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\elmog\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\datasets\\cifar.py:118\u001b[0m, in \u001b[0;36mCIFAR10.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    115\u001b[0m img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(img)\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 118\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    121\u001b[0m     target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform(target)\n",
      "File \u001b[1;32mc:\\Users\\elmog\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\transforms\\transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[1;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[1;32mc:\\Users\\elmog\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\elmog\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\elmog\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\transforms\\transforms.py:277\u001b[0m, in \u001b[0;36mNormalize.forward\u001b[1;34m(self, tensor)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, tensor: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m    270\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    271\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m    272\u001b[0m \u001b[38;5;124;03m        tensor (Tensor): Tensor image to be normalized.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;124;03m        Tensor: Normalized Tensor image.\u001b[39;00m\n\u001b[0;32m    276\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\elmog\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\transforms\\functional.py:363\u001b[0m, in \u001b[0;36mnormalize\u001b[1;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensor, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m    361\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimg should be Tensor Image. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(tensor)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 363\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF_t\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmean\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\elmog\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\transforms\\_functional_tensor.py:922\u001b[0m, in \u001b[0;36mnormalize\u001b[1;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[0;32m    920\u001b[0m mean \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mas_tensor(mean, dtype\u001b[38;5;241m=\u001b[39mdtype, device\u001b[38;5;241m=\u001b[39mtensor\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    921\u001b[0m std \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mas_tensor(std, dtype\u001b[38;5;241m=\u001b[39mdtype, device\u001b[38;5;241m=\u001b[39mtensor\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m--> 922\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43m(\u001b[49m\u001b[43mstd\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43many\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    923\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstd evaluated to zero after conversion to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, leading to division by zero.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    924\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mean\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train the Model\n",
    "myModelInstance, lossfun, optimizer = createTheNet(False)\n",
    "trainLoss, trainedModel = trainTheModel(myModelInstance, lossfun, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
